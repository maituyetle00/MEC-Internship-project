{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy 3000.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZIaq3v_UBBy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    x = x - np.max(x, axis=-1, keepdims=True)\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    kq = -np.sum(t * np.log(y + delta))\n",
        "    return kq\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
        "\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (0,0))\n",
        "    return X_pad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWPwpG6aUxnh"
      },
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "        return dx\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "        return dx\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "        return out\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        return dx\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y = None  # output of softmax\n",
        "        self.t = None  # correct label\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        dx = (self.y - self.t) / batch_size\n",
        "        return dx\n",
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.2):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG5QmKHlU7RJ"
      },
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, 3000) / np.sqrt(2 / input_size)\n",
        "        self.params['b1'] = np.zeros(3000)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(3000, 1500) / np.sqrt(2 / 3000)\n",
        "        self.params['b2'] = np.zeros(1500)\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(1500, output_size) / np.sqrt(2 / 1500)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "       \n",
        "        # create layers\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Dropout1'] = Dropout()\n",
        "\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = Relu()\n",
        "        self.layers['Dropout2'] = Dropout()\n",
        "\n",
        "        self.layers['Affine3'] = Affine(self.params['W3'], self.params['b3'])\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "    def predict(self, x):\n",
        "        k=0\n",
        "        for layer in self.layers.values():\n",
        "            k=k+1\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "    # x:input data, t:correct labels\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1: t = np.argmax(t, axis=1)\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        k=0\n",
        "        for layer in layers:\n",
        "            k=k+1\n",
        "            dout = layer.backward(dout)\n",
        "        grads = {}\n",
        "        grads['W1'] = self.layers['Affine1'].dW\n",
        "        grads['b1'] = self.layers['Affine1'].db\n",
        "        grads['W2'] = self.layers['Affine2'].dW\n",
        "        grads['b2'] = self.layers['Affine2'].db\n",
        "        grads['W3'] = self.layers['Affine3'].dW\n",
        "        grads['b3'] = self.layers['Affine3'].db\n",
        "        return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxKYOmkvVLuI"
      },
      "source": [
        "class Adam:\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key, val in params.items():\n",
        "                self.m[key] = np.zeros_like(val)\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)\n",
        "        for key in params.keys():\n",
        "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
        "            self.v[key] += (1 - self.beta2) * (grads[key] ** 2 - self.v[key])\n",
        "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZRxOoJUraI"
      },
      "source": [
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use python 3.')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "key_file = {\n",
        "    'train_img': 'train-images-idx3-ubyte.gz',\n",
        "    'train_label': 'train-labels-idx1-ubyte.gz',\n",
        "    'test_img': 't10k-images-idx3-ubyte.gz',\n",
        "    'test_label': 't10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "dataset_dir = '/content'\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _load_label(file_name):\n",
        "    file_path = \"/content/\" + file_name\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done 1\")\n",
        "    return labels\n",
        "def _load_img(file_name):\n",
        "    file_path = '/content/' + file_name\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array 2 ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done 2\")\n",
        "    return data\n",
        "\n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] = _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])\n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def init_mnist():\n",
        "    #download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print('Creating pickle file ...')\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "    return T\n",
        "\n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset=pickle.load(f)\n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "\n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "\n",
        "    if not flatten:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4vuq_PeXBr2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1:Settings\n",
        "network = ThreeLayerNet(input_size=784, hidden_size=300, output_size=10)\n",
        "optimizer = Adam()\n",
        "max_epochs = 301\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "epoch_cnt = 0\n",
        "\n",
        "for i in range(1000000000):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "  grads = network.gradient(x_batch, t_batch)\n",
        "  optimizer.update(network.params, grads)\n",
        "  if i % iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(x_train, t_train)\n",
        "    test_acc = network.accuracy(x_test, t_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
        "    epoch_cnt += 1\n",
        "    if epoch_cnt >= max_epochs:\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1tTGaJill_k"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "x1 = np.linspace(0, 300, 301)\n",
        "y1 = train_acc_list\n",
        "x2 = np.linspace(0, 300, 301)\n",
        "y2 = test_acc_list\n",
        "plt.plot(x1, y1, color='yellow')\n",
        "plt.plot(x2, y2, color='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEihKAYLAlqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}